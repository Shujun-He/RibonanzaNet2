jax:

[1.6089498 2.3435106]]
performed step=1 loss=0.6376306414604187
[[1.7873389 1.2243183]]
performed step=2 loss=0.6835348606109619
[[1.9522779 1.3088332]]
performed step=3 loss=0.6469109058380127
[[2.2933042 1.2882427]]
performed step=4 loss=0.6248784065246582
[[4.764158  1.7244284]]
performed step=5 loss=0.6127178072929382
[[1.6076357 1.519154 ]]
performed step=6 loss=0.6044679284095764
[[1.3188491 1.4560087]]
performed step=7 loss=0.5973502993583679
[[2.1926131 1.4570305]]
performed step=8 loss=0.5996001958847046
[[2.3408606 2.4815307]]
performed step=9 loss=0.6053981184959412
[[1.0000604 1.190465 ]]
performed step=10 loss=0.6035183668136597
[[2.3980923 1.5187508]]
performed step=11 loss=0.5967903733253479
[[1.9653141 1.657357 ]]
performed step=12 loss=0.5928848385810852
[[7.285474  4.6978736]]
performed step=13 loss=0.5877612233161926
[[5.701843  4.1741796]]
performed step=14 loss=0.5827609896659851
[[10.1483965  3.979705 ]]
performed step=15 loss=0.5761653780937195
[[3.856068 3.330662]]
performed step=16 loss=0.5698120594024658
[[2.4436898 1.3750182]]
performed step=17 loss=0.5681560635566711
[[2.2121716 1.313542 ]]
performed step=18 loss=0.565510630607605
[[1.6024578 1.2461429]]
performed step=19 loss=0.5616162419319153
[[1.7464665 1.3384604]]
performed step=20 loss=0.5602006912231445
[[6.5492887 5.3121195]]
performed step=21 loss=0.5538361668586731


pytorch:

tensor([[1.6089, 2.3435]])
W0523 20:59:34.786000 759314 .venv/lib/python3.13/site-packages/torch/_logging/_internal.py:1130] [2/0] Profiler function <class 'torch.autog
rad.profiler.record_function'> will be ignored
/usr/local/google/home/jbms/shared/RibonanzaNet2/.venv/lib/python3.13/site-packages/pytorch_ranger/ranger.py:172: UserWarning: This overload
of addcmul_ is deprecated:
        addcmul_(Number value, Tensor tensor1, Tensor tensor2)
Consider using one of the following signatures instead:
        addcmul_(Tensor tensor1, Tensor tensor2, *, Number value = 1) (Triggered internally at /pytorch/torch/csrc/utils/python_arg_parser.cp
p:1691.)
  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)
Epoch 1 Loss: 0.6376320123672485:   0%|                                                                      | 1/632 [00:03<41:56,  3.99s/it]
tensor([[1.7873, 1.2243]])
Epoch 1 Loss: 0.6835356950759888:   0%|                                                                      | 1/632 [00:04<41:56,  3.99s/it]
tensor([[1.9523, 1.3088]])
Epoch 1 Loss: 0.6469115813573202:   0%|▎                                                                     | 3/632 [00:04<11:23,  1.09s/it]
tensor([[2.2933, 1.2882]])
Epoch 1 Loss: 0.6248793751001358:   0%|▎                                                                     | 3/632 [00:04<11:23,  1.09s/it]
tensor([[4.7642, 1.7244]])
Epoch 1 Loss: 0.6127188682556153:   1%|▌                                                                     | 5/632 [00:04<05:50,  1.79it/s]
tensor([[1.6076, 1.5192]])
Epoch 1 Loss: 0.604468951622645:   1%|▌                                                                      | 5/632 [00:04<05:50,  1.79it/s]
tensor([[1.3188, 1.4560]])
Epoch 1 Loss: 0.5973585844039917:   1%|▊                                                                     | 7/632 [00:04<03:37,  2.87it/s]
tensor([[2.1926, 1.4570]])
Epoch 1 Loss: 0.5996795296669006:   1%|▊                                                                     | 7/632 [00:04<03:37,  2.87it/s]
tensor([[2.3409, 2.4815]])
Epoch 1 Loss: 0.6052001780933804:   1%|▉                                                                     | 9/632 [00:04<02:28,  4.19it/s]
tensor([[1.0001, 1.1905]])
Epoch 1 Loss: 0.6030341923236847:   1%|▉                                                                     | 9/632 [00:04<02:28,  4.19it/s]
tensor([[2.3981, 1.5188]])
Epoch 1 Loss: 0.5958083326166327:   2%|█▏                                                                   | 11/632 [00:04<01:50,  5.62it/s]
tensor([[1.9653, 1.6574]])
Epoch 1 Loss: 0.5915589382251104:   2%|█▏                                                                   | 11/632 [00:04<01:50,  5.62it/s]
tensor([[7.2855, 4.6979]])
Epoch 1 Loss: 0.5857361921897302:   2%|█▍                                                                   | 13/632 [00:04<01:25,  7.21it/s]
tensor([[5.7018, 4.1742]])
Epoch 1 Loss: 0.5797910349709647:   2%|█▍                                                                   | 13/632 [00:04<01:25,  7.21it/s]
tensor([[10.1484,  3.9797]])
Epoch 1 Loss: 0.5721966365973155:   2%|█▋                                                                   | 15/632 [00:04<01:09,  8.82it/s]
tensor([[3.8561, 3.3307]])
Epoch 1 Loss: 0.5643152315169573:   2%|█▋                                                                   | 15/632 [00:04<01:09,  8.82it/s]
tensor([[2.4437, 1.3750]])
Epoch 1 Loss: 0.5594652961282169:   3%|█▊                                                                   | 17/632 [00:04<00:59, 10.29it/s]
tensor([[2.2122, 1.3135]])
Epoch 1 Loss: 0.5545523133542802:   3%|█▊                                                                   | 17/632 [00:05<00:59, 10.29it/s]
tensor([[1.6025, 1.2461]])
Epoch 1 Loss: 0.5489629538435685:   3%|██                                                                   | 19/632 [00:05<00:54, 11.16it/s]
tensor([[1.7465, 1.3385]])
Epoch 1 Loss: 0.5452033057808876:   3%|██                                                                   | 19/632 [00:05<00:54, 11.16it/s]
tensor([[6.5493, 5.3121]])
Epoch 1 Loss: 0.5372234072004046:   3%|██▎                                                                  | 21/632 [00:05<00:50, 12.04it/s]
tensor([[1.3820, 1.1239]])
Epoch 1 Loss: 0.5307743562893434:   3%|██▎                                                                  | 21/632 [00:05<00:50, 12.04it/s]
tensor([[1.7941, 1.5171]])
Epoch 1 Loss: 0.5237128501353057:   4%|██▌                                                                  | 23/632 [00:05<00:46, 13.16it/s]
tensor([[1.0843, 1.1754]])
Epoch 1 Loss: 0.5183742493391037:   4%|██▌                                                                  | 23/632 [00:05<00:46, 13.16it/s]
tensor([[11.9625,  7.9430]])
Epoch 1 Loss: 0.5127776479721069:   4%|██▋                                                                  | 25/632 [00:05<00:43, 14.05it/s]
tensor([[1.8081, 1.8852]])
Epoch 1 Loss: 0.5073512643575668:   4%|██▋                                                                  | 25/632 [00:05<00:43, 14.05it/s]
tensor([[1.0242, 1.0497]])
Epoch 1 Loss: 0.5030705156149687:   4%|██▉                                                                  | 27/632 [00:05<00:40, 14.91it/s]
tensor([[1.8055, 1.4915]])
Epoch 1 Loss: 0.4976725248353822:   4%|██▉                                                                  | 27/632 [00:05<00:40, 14.91it/s]
tensor([[5.1526, 3.4941]])
Epoch 1 Loss: 0.49166440347145346:   5%|███                                                                 | 29/632 [00:05<00:38, 15.46it/s]
tensor([[6.9339, 3.1427]])
Epoch 1 Loss: 0.484465687473615:   5%|███▏                                                                  | 29/632 [00:05<00:38, 15.46it/s]
tensor([[2.9376, 1.7147]])
Epoch 1 Loss: 0.4811894355281707:   5%|███▍                                                                 | 31/632 [00:05<00:38, 15.80it/s]
tensor([[3.4509, 1.1615]])
Epoch 1 Loss: 0.4751918110996485:   5%|███▍                                                                 | 31/632 [00:05<00:38, 15.80it/s]
tensor([[7.1228, 6.7208]])
Epoch 1 Loss: 0.4693497654163476:   5%|███▌                           
