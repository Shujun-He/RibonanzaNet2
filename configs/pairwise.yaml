# Model hyperparameters
learning_rate: 0.001 # The learning rate for the optimizer
batch_size: 6        # Number of samples per batch
test_batch_size: 2        # Number of samples per batch
epochs: 10            # Total training epochs
#optimizer: "ranger"       # Optimization algorithm
dropout: 0.1     # Dropout regularization rate
weight_decay: 0.0001
k: 5 #not used
ninp: 384
nlayers: 48
decoder_nlayers: 3
nclass: 8
ntoken: 1000 #AUGC + padding/N token
nhead: 12
#use_bpp: False
use_flip_aug: false
#bpp_file_folder: "../../input/bpp_files/"
gradient_accumulation_steps: 1
use_triangular_attention: false
pairwise_dimension: 128
dim_msa: 32
clip_grad_norm: 1.0
max_len: 177
max_seq: 128

#Data scaling
use_data_percentage: 1
use_dirty_data: true # turn off for data scaling and data dropout experiments


# Other configurations
fold: 0
nfolds: 6
input_dir: "../../input/"
gpu_id: "0"