# Model hyperparameters
learning_rate: 0.004 # The learning rate for the optimizer
batch_size: 2        # Number of samples per batch
test_batch_size: 8        # Number of samples per batch
epochs: 20            # Total training epochs
#optimizer: "ranger"       # Optimization algorithm
dropout: 0.1     # Dropout regularization rate
weight_decay: 0.0001
k: 5
ninp: 384
nlayers: 48
nclass: 2
ntoken: 6 #AUGC + padding/N token
nhead: 12
#use_bpp: False
use_flip_aug: false
#bpp_file_folder: "../../input/bpp_files/"
gradient_accumulation_steps: 1
use_triangular_attention: false
pairwise_dimension: 128
dim_msa: 32
clip_grad_norm: 1

#Data scaling
use_data_percentage: 1
use_dirty_data: true # turn off for data scaling and data dropout experiments

# Other configurations
fold: 0
nfolds: 6
input_dir: "../../input/"
gpu_id: "0"